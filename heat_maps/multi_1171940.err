Loading pytorch-gpu/py3/1.11.0
  Loading requirement: cuda/11.2 nccl/2.9.6-1-cuda cudnn/8.1.1.33-cuda gcc/8.4.1
    openmpi/4.1.1-cuda intel-mkl/2020.4 magma/2.5.4-cuda sox/14.4.2
    sparsehash/2.0.3
+ cd /gpfswork/rech/izg/uvh55jl/journal/heat_maps
+ srun python -u custom_heatmaps.py --prev_id 44
/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.11.0+py3.9.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Traceback (most recent call last):
  File "/gpfsdswork/projects/rech/izg/uvh55jl/journal/heat_maps/custom_heatmaps.py", line 118, in <module>
    demo1((image_paths[i],), target_layer, arch, topk, output_path, cuda, task)
  File "/gpfsdswork/projects/rech/izg/uvh55jl/journal/heat_maps/heatmap.py", line 274, in demo1
    gbp.backward(ids=ids[:, [i]])
  File "/gpfsdswork/projects/rech/izg/uvh55jl/journal/heat_maps/grad_cam.py", line 40, in backward
    self.logits.backward(gradient=one_hot, retain_graph=True)
  File "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.11.0+py3.9.12/lib/python3.9/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/pytorch-gpu-1.11.0+py3.9.12/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.75 GiB total capacity; 30.46 GiB already allocated; 10.69 MiB free; 30.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: jean-zay-ia811: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=1171940.0
